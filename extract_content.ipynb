{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text books \n",
    "# extract vectors\n",
    "# store the vectors in chromadb\n",
    "# langchain chain for ollama call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown widths : \n",
      "[0, IndirectObject(58768, 0, 1862178531280)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(58772, 0, 1862178531280)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(58776, 0, 1862178531280)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(58780, 0, 1862178531280)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(58784, 0, 1862178531280)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(58788, 0, 1862178531280)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(58792, 0, 1862178531280)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(58796, 0, 1862178531280)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text from TB/DavidsonMedicine24th.pdf: 24th Edition \n",
      ",�. . \n",
      "ELSLVlER -Edited by \n",
      "Ian D. Penman \n",
      "Stuart H. Ralston \n",
      "Mark W. J. Strachan \n",
      "Richard P. Hobson \n",
      "II MedicineDavidson’s\n",
      "Principles and Practice of\n",
      "                    P DF  Collected  By:\n",
      "        Dr. Nazmul Alam FarukiSir Stanley Davidson (1894–1981)\n",
      "This famous textbook was the brainchild of one of the great Professors of \n",
      "Medicine of the 20th century . Stanley Davidson was born in Sri Lanka and \n",
      "began his medical undergraduate training at Trinity College, Cambridge; \n",
      "this was\n",
      "Number of chunks from TB/DavidsonMedicine24th.pdf: 1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1010/1010 [1:58:35<00:00,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents in Chroma: 1010\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# List of local PDF file paths for the three textbooks\n",
    "pdf_files = [\"TB/DavidsonMedicine24th.pdf\"]\n",
    "\n",
    "# Container to store all extracted text chunks\n",
    "all_chunks = []\n",
    "\n",
    "# Define the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "\n",
    "# Process each PDF file\n",
    "for file_path in pdf_files:\n",
    "    extracted_text = extract_text_from_pdf(file_path)\n",
    "    print(f\"Extracted text from {file_path}: {extracted_text[:500]}\")  # Print first 500 characters\n",
    "\n",
    "    # Split the extracted text into chunks\n",
    "    chunks = text_splitter.split_text(extracted_text)\n",
    "    print(f\"Number of chunks from {file_path}: {len(chunks)}\")\n",
    "    \n",
    "    # Append the chunks to the all_chunks list\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "# Create Document objects from the chunks\n",
    "documents = [Document(page_content=chunk) for chunk in all_chunks]\n",
    "\n",
    "# Specify the directory to store the Chroma vector database\n",
    "persist_directory = \"chroma_db_davidson\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(persist_directory, exist_ok=True)\n",
    "\n",
    "# Initialize the vector database using Ollama embeddings\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"local-rag\"\n",
    ")\n",
    "\n",
    "# Output the number of documents in the vector database\n",
    "print(f\"Total number of documents in Chroma: {vector_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_19012\\1863015731.py:2: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=local_model)\n"
     ]
    }
   ],
   "source": [
    "local_model = \"llama2\"\n",
    "llm = ChatOllama(model=local_model)\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_db.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    llm=llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# # RAG prompt\n",
    "# template = \"\"\"Answer the question based ONLY on the following context:\n",
    "# {context}\n",
    "# Question: {question}\n",
    "# Make sure the answer is SHORT, CRISP and generated FAST. Try to keep it in one line.\n",
    "# \"\"\"\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:05<00:00,  5.01s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The document is a clinical practice guideline for the prevention and management of thromboembolic disease in intensive care unit (ICU) patients. It provides recommendations for pharmacological and mechanical prophylaxis against deep vein thrombosis (DVT) and pulmonary embolism (PE), as well as evaluation and management of hypercoagulability states. The document covers various conditions associated with decreased platelets and hypercoagulability, including atrial fibrillation, ventilation-perfusion (VA/V/Q) ratio, activated partial thromboplastin time (aPTT), and heparin-induced thrombocytopenia (HIT). It also provides guidance on the use of alternative anticoagulants and hypercoagulability evaluation.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is the document about?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HackDearborn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
